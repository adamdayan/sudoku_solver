Summarise your findings here (see specification).


My initial implementation of the backtrack algorithim finds
that mystery1 is substantially harder to solve than mystery3. Mystery1
took 421546 calls and 513687 microseconds to the 'solve_board()' function as compared to a
mere 14133 calls and 10868 microseconds for mystery3. Mystery2 is insoluble.

However, the finding that mystery1 is harder than mystery3 is a consequence of some relatively arbitrary features of
my algorithim. If I alter 'solve_board()' to first guess 9 (rather than
1) and decrement (rather than increment) the mystery1 requires 16453
function calls and mystery3 requires 16459. This suggests that the
'hardness' wasn't a feature of the puzzle but rather of my solution.
Incrementing guesses from 1 will be highly ineffective when dealing
with a small subset of all boards that contain high numbers in
top-left-hand corner squares, particularly if these squares have few
given peers.

After employing an optimisation that called the solve_board function
on cells with the most filled-in peers first I achieved performance
improvements. mystery1 was solved in 116233 calls and 154604
microseconds; mystery2 took 4952 calls and 4072 microseconds. After
further optimising by adding a helper function that, on the first
'solve_board()' call, attempts to fill in any cells that have only one
possible aswer I achieved further performance enhancements. mystery1
now takes 819 calls and 2773 microseconds while mystery3 took 697
calls and 2261 microseconds. None of this changes their difficulty
ranking but the absolute differences between 1 and 3 have been reduced
signifcantly by improved algorithims. 
